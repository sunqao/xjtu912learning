# 第三章 - 存储器

存储器用于存放程序以及与程序有关的的各类数据，主存储器是存储系统的核心，其用来存储计算机运行期间所需的程序和数据，CPU可以直接对齐进行控制和访问

# 3.1 主存储器概述

## 3.1.1 存储器的分类

存储器是计算机系统中的记忆设备，用来存放程序和数据

### 存储器按在计算机系统中的作用分类

**（1）内部存储器**

内部存储器，简称内存，是一种可以直接和CPU交换数据的存储器，内存包括高速缓存存储器Cache和主存储器（简称主存）

主存主要放的是当前CPU正在执行的程序和数据；Cache是用来解决主存和CPU之间的速度差异的，Cache中的内容都是主存的副本，因此内存的容量只取决于主存的大小，与Cache的大小无关

**（2）外部存储器**

也成为辅助存储器，简称辅存，用来存放大量的，暂时不运行的数据和程序，以及一些需要永久保存的数据；外存可以当作内存的后援储存器

**（3）离线存储器**

也成为备份存储器，主要对在线的数据进行备份

**（4）控制存储器**

控制存储器称为微程序存储器，其用于在微程序控制的计算机中存放微程序，控制存储器位于CPU的内部

### 存储器按存储介质分类

存储介质就是存储器中存放信息的物理单元，作为存储器的物理介质其必须有两种区别明显的物理状态

**（1）半导体存储器**

用半导体器件来存取数据，体积小，功耗低，速度快，常用作内存

**（2）磁表面存储器**

用磁层来存取信息，用磁层依附的物质形状来命名，容量大，速度慢，价格低，非电易失，常用作外存

**（3）光盘存储器**

用磁光材料作为存储介质，利用激光进行信息的存取，非电易失，容量大，耐用性好，可靠，互换性强

### 存储器按存取方式分类

**（1）随机存储器（RAM，Random Access Memory）**

随机存储器中任何单元的内容都能被随机存取，并且存取时间与存取单元的物理位置无关

RAM可以分为动态随机存储器（DRAM），和静态随机存取器（SRAM）两种

其中DRAM中存储的信息如果长时间不访问会发生变化，因此需要定时刷新来维持信息的稳定；而SRAM在加电的情况下所存储的信息可以保持稳定



**（2）只读存储器（ROM，Read Only Memory）**

ROM采用的存取方式也是随机存取，但是ROM在正常工作的时候只能读不能写，其写入需要特殊手段进行，其最大的特点就是非易失性和高可靠性，因此ROM通常作为主存的一部分用于存放系统程序和各种固件

按照写入的方式不同，ROM可以分为

**i 可编程ROM，即PROM（Programmable ROM）**

可以进行一次编程写入

**ii 可擦除可编程ROM，即EPROM（Erasable Programmable ROM）**

可以借助紫外线或其他方式进行多次擦除和编程

**iii 电可擦除可编程ROM，即EEPROM（Electrical Erasable Programmable ROM）**

其与EPROM的区别在于擦除的过程中，不需要借助紫外线和其他方式



**（3）顺序存储器（SAM，Sequential Access Memory）**

顺序存储器中的读写完全按照其在存储介质中的顺序进行，因此在顺序存储器中信息的存取与信息所在的物理位置有关；顺序存储器的读写操作只能顺序的按数据所在的物理位置进行，因此这种存储器的平均存取速度很慢；磁带是典型的顺序存储器



**（4）直接存储存储器（DAM，Direct Access Memory）**

其工作原理与SAM类似，其读写操作分为两步，第一步快速定位到信息所在的一个区域，然后再这个小区域中按照顺序对信息进行准确定位，它的速度位于RAM和SAM之间，也被称为半顺序存储器；磁盘存储器和光盘存储器是典型的DAM



**（5）相联存储器（Associative Memory，AM）**

前面的存储器都是按地址访问存储单元的，但是相联存储器是一种不根据地址而是根据存储内容来进行存取的存储器，可以实现快速地查找快表。既可以按照地址寻址也可以按照内容寻址（通常是某些字段），为了与传统寄存器作区别，称为按内容寻址的存储器。

也就是它可以根据CPU给出的关键字与存储单元中的相应信息进行比较，定位到与关键字匹配的存储单元之后将此单元中的信息取出



以上就是存储器的分类了，目前主存储器主要采用半导体器件作为存储介质，下面来介绍一下半导体存储器的分类

### 半导体存储器的分类

**（1）按制造工艺进行分类**

**i 双极型存储器**

主要由TTL晶体管组成，工作速度快，集成度低，功耗大，价格高，通常用作高度缓存器

**ii 金属氧化物半导体存储器**

也就是MOS型存储器，其可以用来制造多种半导体存储器件，其集成度高，功耗低，价格低，速度比双极型慢，主存储器通常就是由MOS型的存储器构成的

**（2）按信息的可保存分类**

**i 电易失型存储器**

也就是断电后数据丢失，大多数的RAM属于这种存储器

**ii 非电易失型存储器**

断电后的数据保存，ROM就是这种存储器，也有一小部分的RAM属于这种

通常主存就是由ROM和RAM组成的，ROM的内容只能读不能写，断电后信息保存，因此就存放一些系统程序；RAM可读可写，断电后信息丢失，于是就存放一些系统运行过程中的用户数据；RAM和ROM共享主存空间，ROM一般占据较小的主存空间，RAM占据了大多数的主存空间

### RAM存储器的分类

RAM存储器按照其工作方式的不同可以分为以下三类

**（1）静态随机存储器（SRAM）**

SRAM的存储电路由MOS管触发器构成，用触发器的导通和截止状态来表示信息0和信息1，其速度快，信息稳定，不需要刷新电路（关于刷新后文细嗦）；但是集成度低，功耗大，成本高，在计算机系统中，SRAM常用于小容量的高速缓存器

**（2）动态随机存储器（DRAM）**

其利用MOS管的栅极分布电容的充放电来保存信息，其集成度高，功耗低，价格便宜，但是存在漏电，因此必须定时刷新来保证数据不丢失，主存储器通常由DRAM组成

**（3）非易失性存储器（NVRAM，Non Volatile RAM）**

在正常工作的时候NVRAM与SRAM的功能相同，可以随机读写，但是在发生停电等突然事件的时候它可以将SRAM中的信息保存到EEPROM（电可擦除可编程只读存储器）中，使得信息得到自动保护，NVRAM一般用于保护存储系统中的重要信息

## 3.1.2 存储器的层次结构

冯诺伊曼的计算机系统以存储器为中心的结构；计算机要求存储器，速度快，容量大以及价格低，但是这三者通常是矛盾的，为了解决这三者之间的矛盾，一个多层次的存储系统应运而生

剩下的内容比较简单，这里就不多说了

# 3.2 主存储器

## 3.2.1 主存储器的组成

主存储器由存储单元组成的存储体和一组控制电路组成，如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240801192857149.png" alt="image-20240801192857149" style="zoom:67%;" />

下面来一一介绍上述单元

### 存储体

存储体是存储单元的集合用来存放二进制信息；不过为了信息交换的效率，主存与计算机系统中的其他部件交换信息的时候不是以二进制的形式进行的，而是将若干个存储元（一个二进制位）组成一个存储单元，存储单元中的二进制信息被部分或完整的写入或读出

所以每个存储单元都有自己的独立地址，存储单元的位数（即存储字长）是字节的整数倍；一个存储器的就是由这样很多的存储单元组成的

### 寻址系统

寻址系统由驱动器，译码器，以及MAR（主存地址寄存器，用来保存数据传输到的地址以及数据来源的地址）组成，地址译码器接收到来自MAR的n位地址后进行译码，经过译码和驱动之后可以形成$2^n$种地址选择信号，每次选中一个存储单元，就可以对齐进行读或者写操作

每一条译码线都要与其所控制的存储单元相连，驱动器就是为了提高译码线的负载能力而设置的；地址译码线的输出端接入到驱动器的输入端，驱动器的输出端接到所有存储单元

### 读写系统

读写系统由读写电路以及MDR组成，MDR用来缓存CPU发过来的数据，或从主存种读到的数据，读写电路接到CPU的读或者写信号之后产生存储器内部的读写信号，将指定地址单元的数据读出送到MDR种供CPU使用，或者将来自CPU的已经写入到MDR的数据放入存储器的指定存储单元种

### 控制电路

控制电路根据CPU发来的读写命令产生存储器各个部件的时序控制信号

### 读写操作实例

在进行读操作的时候

（1）CPU首先在地址总线上给出访问的存储单元的地址

（2）主存的寻址系统对该地址进行译码，并通过驱动器选中指定的存储单元

（3）CPU在控制总线上发出读的命令

（4）主存的读写控制电路将存储单元中存放的数据发送到数据总线上，并通过数据总线送到CPU中

在进行写操作的时候

（1）CPU首先在地址总线上给出访问的存储单元的地址

（2）主存的寻址系统对该地址进行译码，并通过驱动器选中指定的存储单元

（3）CPU将需要写入的数据发送到数据总线上

（4）CPU在控制总线上发出写的命令，主存的读写控制电路将数据总线上的数据写入到指定的存储单元中

一般而言，存储器的芯片采用M * N位来描述其容量，N表示存储器芯片中每个存储单元的字长（称为片字长），存储单元是最小可寻址单位，M表示存储单元的个数；片字长一般取1, 4, 8, 16...k位，每一个存储单元都由存储体中的k位组成

### 寻址系统译码器译码的方式

所谓译码方式，其实就是寻址系统的译码器得到存储单元的地址后怎么通过译码器连接确定存储单元的过程，这里有两种方式，线选法确定存储单元和重合法确定存储单元

**（1）线选法**

线选法其实就是译码器得到存储单元的地址后输出的字线直接连接到对应的存储单元中，直接将这个地址处的存储单元全部取出

我们假设有一个1K * 8位的存储器芯片，其采用的是1024 * 8的存储矩阵，于是我们知道存储单元的个数应该为$2^{10}$个，所以地址位数应该为10位，因此线选法的硬件电路如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803165010102.png" alt="image-20240803165010102" style="zoom:67%;" />

上图中一个存储元的左边一个数字是其所在存储单元的地址，右边是其在一个存储单元中的第几位，一个字线对应一个存储单元，一个字线对应一套驱动电路，因此就有1024套驱动电路

当地址输入到译码器中，译码器确定了存储单元地址然后读/写进CPU的过程如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803165551433.png" alt="image-20240803165551433" style="zoom: 50%;" />

**（2）重合法，双译码结构**

重合法将给出的地址拆成了两个组，一组是行地址，一组是列地址，行地址得到的行选择线和列地址得到的列选择线重合的存储单元就是需要读写的单元

假设有一个1K*1位的存储芯片如下所示，这里一位是一个存储元，也是读写的一个存储单元，采用32 * 32的方式进行排列：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803165903394.png" alt="image-20240803165903394" style="zoom:67%;" />

同样是1024个存储单元，所以地址线的数量应该是10根；有32行，所以行地址译码器分配5根地址线，输出32根行选择线，对应32套驱动电路；有32列，所以列地址译码器分配5根地址线，输出32根列选择线，对应32套驱动电路

所以总的驱动电路就是64套，译码选择过程如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803170354136.png" alt="image-20240803170354136" style="zoom:50%;" />

## 3.2.2 主存储器的性能指标

### 存储容量

也就是主存可以容纳的存储单元的个数

如果按字编址，那么一个存储单元就是一个字，存储容量就是：存储单元个数 * 存储字长，单位是位(b)，这里存储字长一般等于机器字长

如果按字节编址，那么一个存储单元就是一个字节，存储容量就是存储单元个数，即存放的字节数，单位是字节(B)

需要注意的是，如果按字编址的话存储容量的写法得用存储单元个数 * 存储字长的写法，如果按字节编址就直接写成字节数；这样做是因为存储字长在不同的机器上是不一样的，统一用位表示，并且写成乘积的形式容易理解，而字节则是一个统一的单位

存储单位换算如下：

```c
1 TB = 1K GB
1GB = 1K MB
1MB = 1K KB
1KB = 1K B
1B = 8b
上述1K表示1024，即2^(10)
```

### 存储速度（读写速度）

通常用存取时间和存取周期表示

存取时间称为存储器的访问时间，就是指启动一次存储器写（或读）到完成该操作的时间

读出时间是存储器受到有效地址，到产生有效输出的时间

写入时间是存储器收到有效地址，到写入存储单元的时间；通常写入时间和读出时间相等，两者统称为存储器的读写时间

存取周期是指存储器完成一个完整的读写所需要的时间，其包括读写时间以及后面的电路恢复时间，它是一个更加完整的过程，因此其时间略大于读写时间

### 存储器带宽

指单位时间内存储器的存取信息量，单位为W/s, B/s, 或b/s，计算公式为：
$$
存储器带宽 = \frac{每个存储周期可访问的位数}{存取周期(s)}
$$
存储带宽就是以存储器为中心的计算机系统获取信息的速度，通常通过缩短存取周期，增加存储字长，增加存储体等方式增大带宽

## 3.2.3 SRAM

### SRAM存储元

SRAM即静态随机存储器，其静态的意义就是只要保持电源供电，SRAM就能稳定保存数据，SRAM的基本特征是使用一个双稳态的触发器作为存储元

不是重点，略，注意mos管中间一条线为高电平时是导通状态，然后导通状态下两边的线其实电流成比例，因此一条线是高电平另一条线也是高电平，记住这个就好，其他的先看书理解以下即可

### SRAM芯片举例

#### CY7C1011CV33 SRAM

这个芯片的存储容量为128K * 16位，结构如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803185900655.png" alt="image-20240803185900655" style="zoom:67%;" />

其包括$IO_0 - IO_7$的低字节数据线部分，以及$IO_8 - IO_{15}$的高字节数据线部分，用来将数据读出写入

以及片使能$\bar{CE}$，主存一般是由若干个上图的芯片组成的，因此每次访存涉及的芯片也不一样，这里的片使能为低电平有效，也就是上图中$\bar{CE}$对应的那条细线为低电平的时候表示本次存储器的访问涉及这个芯片

输出使能$\bar{OE}$，低电平有效，即表示$\bar{OE}$对应的那根细线为低电平的时候是从存储器中读取数据

写使能$\bar{WE}$，低电平有效，即表示$\bar{WE}$对应的那根细线为低电平的时候是从存储器中写入数据

同样有高字节使能$\bar{BHE}$和低字节使能$\bar{BLE}$，分别表示要访问一个字中的高字节还是低字节

当$\bar{CE}$和$\bar{WE}$均为低电平的时候，数据线上的数据被写入存储单元，当$\bar{CE}$和$\bar{OE}$均为低电平的时候，存储单元上的数据被读出

一般这样一个芯片会使用一个逻辑符号框图表示：

![image-20240803190836533](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803190836533.png)

这个框图的内部写上芯片名字以及片容量，还有在对应的引脚处写上引端名字，引端名字是芯片引脚的逻辑定义，是由厂家给出的

在方框的外部写上信号名字，这里的信号是用户自定义的，不过不管是引端名字还是信号名字，都指的是那根细线，而不是细线与圆圈组成的整体

当然，上述引脚线是逻辑引脚，当然还包括电气引脚，比如电源线和接地线等等，这里忽略



#### Intel 2114 SRAM

这个芯片的容量为1K * 4位，存储矩阵是64 * 64，结构如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803191341971.png" alt="image-20240803191341971" style="zoom:67%;" />

其地址译码采用的是重合法，$A_3 \sim A_8$是行地址，$A_9, A_2 \sim A_0$是列地址

其同样有一个片选信号，是低使能有效

控制读写的只有一个写使能信号，同样是低使能有效，表示低使能写信号有效，表示写入数据

其逻辑框图如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803191618280.png" alt="image-20240803191618280" style="zoom: 50%;" />

### SRAM的读写时序

对于一个确定的芯片而言其读写时序是确定的，这里以CY7C1011CV33 SRAM为例

**（1）其读数据的信号如下所示：**

![image-20240803194046108](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240803194046108.png)

上图中的地址线和数据线两根的原因是输入一串数据中有0也有1，这里变化一次表示有效无效的变化

首先是CPU在地址总线上发出有效地址，并且通过片选信号$\bar{CE}$选中这块芯片，如上图中的橙色线所示，此时存储器对地址信号进行译码并选中相应的存储单元

经过一段时间后，读使能信号和高低字节使能信号有效，如上图中的紫色直线，并经过一段延迟时间后数据有效输出相应的高低字节，上图红色线

读出过程中存在两个约束：

（1）从发出使能信号$\bar{CE}$橙色线，到数据有效真正读到数据上图红色线，注意是红色线，原图有误，需要经过一个时间tace

（2）从读使能有效紫色，到数据真正有效红色，同样有一个时间tdoe

tace的时间最短是10ns，因此如果cpu发出了使能有效后真正读到数据就得10ns之后了

并且撤销过程也有两个约束：

（1）从撤销使能信号$\bar{CE}$蓝色，到数据线上的数据无效有一个时间延迟thzce

（2）从撤销读使能信号$\bar{OE}$到数据上上数据无效（撤销数据）有一个时间延迟thzoe

这就说明CPU发出了撤销信号之后数据真正从数据线上撤销还需要有一个时延，在这个时延中数据线仍被占用不能被其他数据使用，所以从发出使用这个存储器的信号开始（橙色）到这个存储器真正可以被再次使用（绿色）这一段时间trc + thzce是这个存储器的恢复时间

从片使能信号发出，到片使能信号结束的时间trc，为存储器芯片的读出时间

只要不违反上述两个约束就可以随意使用这个芯片，比如可以让$\bar{CE}$和${\bar{OE}}$同时有效，然后等tace的时间读到数据

**（2）写时序信号**

不是重点，不再赘述

## 3.2.4 DRAM

### DRAM存储元

不是重点，不再赘述，看书即可

### DRAM刷新操作

DRAM存储元中的电荷会因为电荷泄露而引起DRAM所存的信息衰减，所以必须定期对电容补充电荷，这种操作被称为刷新操作

DRAM存储器能维持的信息的最长时间称为最大刷新间隔，一般为2ms, 8ms, 64ms等，最大刷新间隔其实也就是某个存储元两次刷新时间的最大间隔，对于一堆的存储元整体来看，一个最大刷新时间间隔中一个存储体的所有存储元至少要被刷新一次，在这个刷新间隔中刷新之外的时间可以对存储体进行读写操作

由于在进行读的操作时存储元会自动再生操作补充电荷，所以刷新就可以通过读的操作进行；一次刷新操作所需要的时间就是一次读操作所需要的时间

刷新操作是按照矩阵的行进行的，只需要送出行地址和刷新信号即可，只不过行地址不需要外部提供，DRAM内部有一个行刷新计数器用于产生行地址

为了保证正常工作，必须在最大刷新间隔中对所有的存储元进行一次刷新，安排存储元中的各行的刷新时间的策略称为刷新方式

**（1）集中式刷新**

集中式刷新是指将全部的存储单元集中在一段时间内刷新，在整个刷新间隔中，前一部分时间用于正常的存储器读写和保持操作，后一部分用于所有存储器的刷新操作

在进行集中式刷新的时候是对存储体逐行刷新的，因此不能进行正常的存储器读写操作，这个称为存储器的死时间或读写死区，目前很少采用这种方式

假设有一个64K * 1的DRAM芯片，存储体为256 * 256的矩阵，最大刷新间隔是2ms，也就是第一个存储元刷新间隔是2ms，存取周期是$0.5 \mu s$，每行刷新因此刷新一行就是一个读取周期，刷新256行就需要需要256个存取周期

注意刷新间隔的定义，并不是在一个刷新间隔内这个存储元始终不能被读取，而是这个存储元可以保持数据的最大间隔，在这个间隔中这个存储元不是一直处于无法读取的状态，对于整个存储体也是这样的，并不是一行行刷新完了之后直接开始从第一行又开始刷新，而是等到第一行的数据无法保持了之后再继续一行行刷新

在一个刷新间隔中，256个刷新存取周期存储器不能进行正常读写，也就是刷新间隔中的后一部分时间，然后刷新周期的前一部分时间都可以正常读取数据，所以其余的3744个存期可用于正常的读取

注意注意的是刷新时间和读取时间各自都是整块连在一起的时间，过程就是上一个刷新间隔结束，整个存储器可以正常读取数据，然后第一行的存储元数据无法保持了，就开始整个集中一行行开始刷新，这个集中一行行刷新就是死时间，结束之后就进入了下一个刷新间隔

**（2）分散式刷新**

分散式刷新是将刷新周期分散到每个存取周期中进行，每个存取周期的前半段用于读写保持数据，后半段用于刷新操作，分散式刷新将存取周期扩大到了两倍；意思就是本来正常存取周期都是0.5us，但是呢人为将其扩大到了1us，这样前半段用于读写，后半段用于刷新，将刷新操作融入到了每次读写操作中了；这样就克服了死时间，一个刷新周期中，不管哪个时间段都可以随便使用存储器（注意一般来讲存储器中在一个刷新间隔中的所有行都会被访问到，不必纠结哪一行一直不被访问无法刷新的问题）

仍然是上述64K * 1的DRAM芯片，存储体为256 * 256的矩阵，最大刷新间隔是2ms（指某一行的存储元可以保持信息的最大时间间隔，也就是某行刷新一次之后最多经过2ms必须再刷新一次），存取周期是1us，因此在这2ms中就包含有2000个存取周期，这2000个存取周期中存储器都可以正常读写，假设这2000个存取周期都在读写并且每行都被读写到了，那么就刷新了2000次，平均下来每行刷新了7.812次，比集中式每行多刷新了6.812次

但其实2ms中只需要保证每行刷新一次，即刷新256次即可，但是强迫每次读写时也进行刷新，这就造成了多次刷新，浪费了时间

**（3）异步式刷新**

异步式刷新是指，其将所有行的刷新操作平均分配在一个刷新间隔中，使得在一次最大刷新间隔中，每一行都会被刷新并且只被刷新一次

这样做首先就不存在时间的浪费了，因为每行都只刷新了一次，并且由于是分散到一个刷新间隔中，也就不存在有一整块时间不能读写使用的死时间问题了

仍然是上述64K * 1的DRAM芯片，存储体为256 * 256的矩阵，最大刷新间隔是2ms（指某一行的存储元可以保持信息的最大时间间隔，也就是某行刷新一次之后最多经过2ms必须再刷新一次），存储周期是0.5us，在这2ms的刷新间隔中将256次刷新平均分配，那就是2000us / 256 = 7.8us得刷新一行，这7.8us其实还是有0.5us是不能读写的，但是从宏观上看这个7.8us中大部分时间都是可以读写，而从概率上讲就必然比一个整块的死时间对存储器的使用影响小很多，也就克服了死时间的影响

### DRAM存储器芯片举例

DRAM一般集成度非常高，因此芯片的引脚就很多，为了减少芯片引脚一般讲地址分为行地址和列地址两部分，并且两部分分别在不同的时间段使用同一组地址引脚，这样就将实际的地址引脚减少为原来的一半了，因此每增加一根地址引脚其实是行列地址个增加了一位，芯片的总容量其实扩大了4倍

为了区分行列地址，又引入了行地址选通信号$\bar{RAS}$和列地址选通信号$\bar{CAS}$，同时为了进一步减少引脚，通常将片选信号$\bar{CE}$与行地址选通信号$\bar{RAS}$合在一起使用，下图是一个非常典型的DRAM内部结构示意图，我们需要再加上一个写使能$\bar{WE}$来区分是写入还是读出：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805113337001.png" alt="image-20240805113337001" style="zoom:67%;" />

DRAM的逻辑框图如下所示：

![image-20240805113400474](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805113400474.png)

### DRAM的读写时序

不是重点，看看书即可

## 3.2.5 新型DRAM

不是重点

## 3.2.6 只读存储器和闪存存储器

只读存储器即ROM在前面已经介绍过，它比SRAM和DRAM的最大特点就是只能读处不能写入，并且其中的信息在断电之后不会消失，具有非电易失性，其通常用来保存一些重要的数据，比如计算机启动的时候的Bios芯片等等

其主要用途就是软件固化，**写到ROM中的软件以及芯片称为固件**

以下内容都不是重点，看看ppt知道概念即可，电路图原理什么的不用在意

### 只读存储器

**MROM（MASK ROM）**

掩模式ROM，也就是在生产过程中采用掩模式（光刻图形技术）一次性写入的，其一旦制成之后内容就不能再改写，因此只适用于存储永久性的程序和数据

**PROM（Programmable ROM）**

可编程ROM，出场之后用户可以使用专门的ROM写入器进行写入操作，但是只能写入一次

**EPROM（Erasable Programmable ROM）**

擦除可编程ROM，是一个可以多次写入的ROM，用户使用转变的编程器来完成

**EEPROM（Electrically Erasable Programmable ROM）**

电可擦除可编程ROM，其跟EPROM类似，只不过采用的是电擦除技术实现数据的擦除

### 闪速存储器

即Flash Memory，简称Flash存储器或者闪存，其与EEPROM非常类似，也是一种点可擦写ROM，其与EEPROM相比主要是速度快，成本低，容量大，低功耗，可以再联机的情况下进行电擦除和改写，因此又称为快擦型电可擦除可编程ROM

## 3.2.7 存储器容量的扩展

根据上文我们知道一个存储芯片的容量是有限的，因此想要获得更多的容量就必须将多个存储芯片组合起来满足实际容量的需要

扩展包括三种，位扩展，子扩展，和字位扩展；下文以SRAM为例来说明这三种扩展

### 位扩展

位扩展是增加存储器的存储字长，进行位扩展后的存储器的总字数与单个芯片的总字数保持一致，因此通过位扩展构成的存储器系统所需的总的存储器芯片个数就是：
$$
\frac{存储器字长}{单个芯片的字长}
$$
位扩展的基本方法：

（1）各个存储器芯片的地址线，片使能线，读写控制线分别按同名端并联起来，所谓并联就是多条线合在一起变成一条线进行控制

（2）各个存储器芯片的数据线分别引出串联起来作为总的存储器的数据线

如下图所示，是一个SRAM存储器位扩展的逻辑图：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805152546692.png" alt="image-20240805152546692" style="zoom:67%;" />

上图中是一个用8片1K * 1位的SRAM芯片组成一个1K * 8位的存储器的例子，其片使能线，读写控制线分别并在一起用一条线控制，数据线引出当作存储器数据线

### 字扩展

字扩展与位扩展相对，是将多片存储芯片连在一起来扩充整个存储器的字数，进行字扩展之后的存储器字长与单个存储芯片的字长保持一致，所以组成一个存储器系统的总的存储器芯片的个数就是：
$$
\frac{存储器的总字数}{单个芯片的字数}
$$
字扩展的基本方式：

（1）将各个存储器芯片的读写控制线，数据线并联起来；注意这里数据线要并联起来，这里的并联意思是指用到哪一片芯片哪一片芯片的数据线就将其数据输入到并联之后的一条总的数据线上作为存储器输出的数据

（2）存储器的地址部分分为高地址和低地址部分，高地址连接一个译码器形成各个存储器芯片的片使能信号，低地址则与每个芯片的地址信号相连，这样扩展了字数之后高地址就形成了一个”段“用来选择使用哪一个芯片，低地址就跟芯片中的地址一样，用来选择存储单元

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805155449352.png" alt="image-20240805155449352" style="zoom:67%;" />

上图就是一个字扩展的例子，用8片8K * 8的SRAM组成一个64K * 8的存储器，这些芯片的读写控制信号连在一起统一读写，然后每个芯片的数据线也是并联在一起，加粗的意思就是高地址译码后的片选信号选择了哪个芯片，哪个芯片的数据就作为存储器的8位数据输出

上图中的高三位地址译码之后分别连接8个芯片用来选择是哪一个芯片，低13位地址就作为每个芯片中的地址

### 字位扩展

字位扩展的意思就是即增加存储字数，又增加存储字长，因此所需的总的芯片数量就是：
$$
\frac{存储器的总容量 * 存储器的存储字长}{单个芯片的总容量*单个芯片的存储字长}
$$
其实也就是总的存储器位数除以单个芯片的总位数（上面两种也可以这样计算）

字位扩展的方法为：

（1）所有芯片的读写控制线并联在一起统一控制，跟上面两种扩展方式一样

（2）数据线沿着方向同名端，并联并引出作为总存储器的存储子长的一部分，下图中就是沿着横向并联引出作为存储器存储字长的低8位

（3）地址线仍然分为高地址和低地址，高地址线译码后作为片选信号选择纵向的某一列作为一个小段，因此纵向的片选信号应该并联在一起统一被选中，**所以横向的芯片摆在一起是作为字扩展使用，纵向的芯片摆在一起是作为位扩展使用**

（4）地址线的低地址部分用来选择纵向一列的芯片组成的一个位扩展的小段中的存储单元，因此纵向一列的芯片的地址线应该是并联在一起的，当传递某个地址时表示纵向所有芯片的这个地址对应的存储单元都被选中，需要将数据输出，只不过这些芯片的数据分别作为总的存储器的存储字长的高位和低位输出

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805161157484.png" alt="image-20240805161157484" style="zoom:67%;" />

上图是16块8K * 8SRAM芯片组成的64K * 16存储器的逻辑图

上图中纵向一列芯片用于位扩展，上侧芯片的数据是整个存储器存储字长的第8位，下侧芯片是整个存储器存储字长的高8位；当地址从外界输入之后，上下两片芯片对应地址的存储单元都被选中取出结合一起之后形成总存储器的16位存储字长

上图中横向一串芯片用于字扩展，因此外界地址线的高两位连接译码器来进行片选，选中一列上下两个芯片组成了总存储器的一个存储字长；注意上图中的并联线（也就是上图中加粗的线）其表示是如果是从芯片读出数据，那么并联之后的总的一条线就是这个芯片上的数据，而如果是从外界来的数据，那么到每个芯片分支线上也都将是外界数据，只不过我们通过片选信号屏蔽了这些数据，使得只能写入到给定的地址对应的芯片中

### 其他芯片的扩展

对于ROM来说其通常没有$\bar{WE}$引脚，连接方式与SRAM基本一致

对于DRAM，其容量的扩展方式与SRAM基本一致，但是地址线，片使能线等连接还需要特殊处理，DRAM的扩展与SRAM的区别如下：

（1）根据上文介绍，DRAM的地址线通常采用多路复用，也就是其中的每个芯片都分为行地址和列地址，并且行列地址共用每个芯片的地址线，并且行列地址分时输入，而所有芯片组合在一起作为总的存储器的时候外界可不管分时不分时，而是统一将一个总的地址输给存储器，因此这就需要一个地址多路选择器来分时对总地址拆分，分时选择输给里面的芯片，地址多路选择器一般由DRAMC来控制，后文细嗦

（2）DRAM的芯片为了减少引脚通常将行选择信号$\bar{RAS}$作为片选信号，那么当采用字扩展之后，外界的高地址用来选择那一小段的芯片，同时呢外界还得跟内部的芯片一样有行选通信号和列选通信号用来控制整个芯片组的行选通和列选通；对于外界的行选通信号，其与外界地址的高位部分一起连接一个译码器，这个译码器的输出作为片选信号表示选择字扩展中一组芯片组成的一个小段，下图中的纵向就是字扩展，表示横向的四个芯片组成了一小段，外界的行选通信号和高地址位译码之后分为四条线，每一条线表示选择纵向的某一行，同时表示这一行的芯片行选通，此时的地址是行地址；对于列选通信号和读写控制信号，这两个信号所有的芯片都并联在一起统一控制；如果DRAMC有译码功能的话下图中的译码器可以省略

（3）DRAM芯片的刷新操作，需要有刷新地址计数以及刷新定时等外围电路，这些电路也通常由DRAMC芯片提供

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805163838389.png" alt="image-20240805163838389" style="zoom:67%;" />

上图就是16个256K * 8的DRAM芯片组成的1M * 32位的存储器的逻辑图，横向一组表示位扩展，因此横向一组芯片的地址需要连在一起，表示当外界给出一个地址之后横向所有芯片都应该选择一样的存储单元，合在一起组成总的存储器的一个存储字长；横向的行选通信号也应该连在一起，行选通同时表示片选信号，表示这一行的芯片作为一小段，外界的低地址部分就在这一组芯片中选择存储单元，所以横向的四个芯片的数据线应该串在一起组成总的存储器的一个存储字长

纵向四个芯片表示的是字扩展，所以片选译码器应该分出4个片选信号（与行选通信号合并）分别连接纵向的四个芯片；同SRAM，纵向的四个芯片的地址线是并联在一起的，当外界的第地址部分给出地址之后纵向的四个芯片都会收到这个地址，根据片选信号决定纵向的哪个芯片得到的这个地址是有效的；其他的就不多说了

## 3.2.8 存储器与系统总线的连接

主要涉及地址线，数据线，和控制线的连接

### 数据线的连接

存储线的数据线必须与系统总线的位数一致，并且逐位连接，通过位扩展形成的存储器，扩展之后的总的存储器的存储字长，也必须与总线的位数一致

### 地址线的连接

单片存储器的地址线与系统总线的地址线一一对应，对于字扩展形成的芯片，外界的地址总线的位数肯定比存储器中的芯片的地址线位数多，这样可以将外界的地址总线的高地址位数作为片选信号，低地址用来字扩展中的每一段的地址，上文有说过，这里不再多嗦

### 控制线的连接

与存储器有关的控制线主要就是读写控制，其与总线中的读写控制直接相连即可

### SRAM/ROM与CPU的连接

对于CPU来讲，其发出的高位地址连接译码器作为片选信号，低位地址送到存储器确定存储单元的地址，但是CPU发出的地址不一定都是主存的地址，还有可能是访问IO的地址，因此需要有一个$\overline{MREQ}$作为访存控制信号，这个信号仍然是低电平有效，只有它有效了译码器发出的片选信号才有效

下面是一个ROM和SRAM结合与CPU连接的例子，2片1K * 8的ROM芯片，以及6片1K * 8的SRAM芯片采用字扩展，形成了一个8K * 8的存储器

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805173847825.png" alt="image-20240805173847825" style="zoom:67%;" />

上图中的ROM一般存放系统程序，占据的是低地址空间，RAM存放用户程序通常放在第地址空间

上图的译码器采用的是74138译码器（3-8译码器），其中ABC是输入变量段，连接总线CPU发来的地址的高位，输出是8个片选信号；控制端是$\overline{G_{2A}}, \overline{G_{2A}}, G_1$，只有$\overline{G_{2A}}, \overline{G_{2A}}$都是低电平，G1是高电平，三者同时有效的时候译码器才能工作；上图其他部分就不多嗦了

### DRAM与CPU的连接

根据上文所述，DRAM由于刷新机制以及行列地址机制其不直接与CPU相连，而是通过一个DRAMC芯片（DRAM控制芯片）与CPU相连

如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805180232851.png" alt="image-20240805180232851" style="zoom:67%;" />

上图的虚线框中就是DRAMC的逻辑控制框图，下面来分别介绍

（1）**刷新地址控制计数器**，这个模块向DRAM提供刷新行地址，并自动顺序计数到下一行的地址，刷新地址计数器提供刷新地址，而地址总线提供的是行列地址

（2）**地址多路选择器**，其在行地址，列地址，刷新地址三者选一送给DRAM

（3）**刷新定时器**，根据刷新方式控制刷新时间，当需要刷新的时候发出刷新请求信号，不过并不是请求刷新的时候一定会刷新，因为还有读写信号，所以就需要仲裁电路决定一种访存方式

（4）**仲裁电路**，在CPU的访存请求，刷新请求中决定一种访存方式

（5）**定时发生器**，仲裁电路决定好访存方式之后由定时发生器产生一系列DRAM工作需要的信号，行列选通信号，读写控制信号，刷新信号等等，这玩意儿还挺重要，其最直接决定了对DRAM是读还是写还是刷新以及决定了行列地址的选择还有刷新地址的开始

当然上述只是最简单的连接方式，我们仍然需要考虑时序配合，速度匹配，负载能力等等

## 3.2.9 两个例题

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805181336213.png" alt="image-20240805181336213" style="zoom:67%;" />

（1）

因为计算机是16位的，而存储器芯片是4位的，由于上文中的连接关系，存储器的存储字长必须与数据总线位数保持一致，所以存储字长也是16位的，通过8K * 4位的DRAM芯片扩展而来

地址空间大小是$2^{20} = 1M$，所以最大主存空间就是$1M * 16$位

（2）

总的模板快，显然就是$\frac{1M * 16}{64K * 8} = 2^5 = 32$块

每个模板块内部，显然就是$\frac{64K*8}{8K*4} = 16$片RAM芯片

（3）

问的是CPU如何选择模板块，其实就是CPU的地址码如何编排

因为模板有32块，两两模块板组合一起位扩展扩展成16位，所以有16组模块板进行了字扩展，因此模块组的片选应该有16个，所以CPU最高位应该分配4位进行模板块组的选择

一个模板块组中，仍然是两两DRAM芯片组合进行位扩展，所以一个模块组应该有8组芯片进行字扩展，因此模块组中应该有8个片选取选择芯片，因此地址码应该再分配次高的3位进行模块组内部的片选

剩下的13位进行芯片内部地址的选择

**第二个例题**

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805190738742.png" alt="image-20240805190738742" style="zoom:67%;" />

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805190750745.png" alt="image-20240805190750745" style="zoom:67%;" />

首先CPU的地址线有16位，所以总的主存空间理论大小最大就是$2^{16}*8$位即64K * 8位

但是说了只将16383以内作为主存空间，所以总的主存空间应该是$16384 * 8 = 2^{14} * 8 = 16 K * 8$位

有$4K * 8$是作为系统的，这一部分需要使用ROM来扩展，当字扩展和位扩展都可以实现的时候采用位扩展，因为字扩展还需要进行片选译码，而位扩展只需要引出几条线即可，所以就采用两片4K * 4的ROM组成一个4K * 8的ROM

还剩下12K * 8的空闲需要用RAM扩展，肯定采用4K * 8最方便，所以就接着使用3片4K * 8的RAM

**然后是地址线的连接**

74138是一个3 - 8译码器，会输出8根片选信号，输入是3根

首先是上述采用芯片的内部选址，每一个都是4K（两片ROM由于是位扩展所以寻址也是4K），**因此需要12根地址线用作内部选址**

3-8译码器其实应该有8条线输出进行片选，不过我们可以不全用，其输入应该是3根地址线，**所以需要3根地址线作为3-8译码器的输入**

**3-8译码器的3就表示输入的三根译码器：_  _  _，组成了8个片选，也就是将内部的4K的地址空间分成了8段**

 对于ROM的4K空间，本来就是12根地址线作为内部选址，因此其只需要$4K / 2^{12} = 1$个片选信号，又由于是题中说的最小的4K地址，所以就连着最小的一段，即3-8译码器的0输出端

而RAM有12K的空间，4K作为一段，根据题意又是按顺序的，所以RAM占用3段4K空间，因此需要3-8译码器中的1， 2， 3输出端；而刚好就是3个4K*8的RAM，所以就是每个RAM芯片作为一个4K的地址端连着一个译码器的输出端

12根地址线作为内部选址，3根作为译码器的输入，分别将4K的内部地址划分了8端，但是只用到了前四段，还剩下一根地址线可以作为38译码器的控制端

**最后是数据线的连接**

两片ROM都是4K * 4，所以两片ROM的数据线应该串起来分别作为CPU数据线的高低4位，而剩下的RAM的8位直接并联作为8位即可

然后ROM没有读写控制信号，所以最终的连接方式如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240805195120546.png" alt="image-20240805195120546" style="zoom:67%;" />

## 3.2.9 微处理器与存储器的连接举例

这里我们以8086的处理器为例来说明

16位的微处理器8086其地址总线的宽度是20位，即有20位根地址线，并且存储器采用的是字节编址，所以其存储空间大小就是1MB，

但是8086却采用的是两个512KB的存储器组合成的1MB的存储器空间，这两个存储体芯片，一个存储器的存储单元作为总的存储空间中的奇数地址对应的存储单元，一个存储器的存储单元作为总的存储空间中的偶数地址对应的存储单元：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807165112164.png" alt="image-20240807165112164" style="zoom:67%;" />

注意上图中的两个存储体内部的存储单元还是按顺序的，只是两者分别表示了总的存储空间中的奇数地址和偶数地址

上图中的最低位地址线A0以及存储体选择信号$\overline{BHE}$作为高字节还是低字节选择，奇数地址对应的存储体连接数据线的高八位，偶数地址对应的存储体对应数据线的低八位，两者信号配合选址如下所示：

![image-20240807170008945](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807170008945.png)

8086采用的是小端方式存储，很显然如果用边界对齐的方式存储的话，那么对于一个字或者双字，其低字节部分肯定是在总的地址空间中的低地址部分，并且存放在偶存储体中，而低字节就是这个字或双字的地址（因此字或者双字的地址一定是偶数），对于一个字而言，其高字节和低字节分别存放在两个存储器中，所以就可以在一个存储周期中读取出来

> 因为19位的地址总线发送一个地址，两个存储体中19位地址相同的存储单元属于同一个字，分别是低字节和高字节，在总的地址空间中，一个偶地址字节与比起大1的一个奇地址组成了一个字，分别对应两个存储体内部19位地址相同的存储单元

但是如果不是采用边界对齐的方式存储字，那就有可能这个字的高字节在偶存储体，并且低字节同样在偶存储体的情况，这样就需要两个存取周期将其取出了，下图是CPU读取存储体中的数据的情况：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807170815289.png" alt="image-20240807170815289" style="zoom:67%;" />

上图中的(d)就是不采用边界对齐，就可能出现一个字的低字节放在了奇地址中，高字节放在了偶地址中，当CPU发出一个19位的地址信号的时候，第一次读取是将奇地址中的数据与其上面的偶地址中的数据读出，CPU必须再发出一个地址信号才能将下面的偶地址中的数据读出来

# 3.3 相联存储器

## 3.3.1 相联存储器的工作原理

上文中的RAM和ROM都是按照地址进行访问的，而相联存储器则是可以按照内容进行访问

相联存储器在写操作的时候仍然是按照地址访存，但是在读操作的时候除了可以按照地址访存之外，还可以将CPU给出的关键字与存储器中的信息进行匹配比较，定位到与关键字匹配的存储单元后可以直接将此单元中的信息读出，有点像是数据库中的关键词

相联存储器就是用存储单元中的某个存储项的内容来对存储器进行寻址，这个用来定位的存储单元的字段称为关键字，简称键（key）；因此相联存储器中存储单元的信息都是由关键字和数据两部分组成

相联存储器由存储体、检索寄存器、屏蔽寄存器、匹配寄存器、数据寄存器、比较电路和译码电路等组成，如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807172523611.png" alt="image-20240807172523611" style="zoom:67%;" />

**下面以读出过程来说明其工作的原理**

首先是检索寄存器，其中存放用于查询的检索字，其位数与相联存储器存储单元的字长相等，为了确定检索寄存器中的检索字哪些是关键字，就需要屏蔽寄存器中存放屏蔽码，屏蔽码的位数与检索寄存器的位数相等，且屏蔽码中关键字的位数为1，其余位被清零；上图中检索关键字中的第8位到第11位为关键字，所以屏蔽码的值就是0000 1111 0000 0000

然后是比较电路，检索寄存器与相联存储器操作的结果会在比较电路中与所有存储单元的对应位进行比较，如果某个存储单元中的内容与关键字相符，则将存储单元所在匹配寄存器中相应位置为1，匹配寄存器的位数等于相联存储器的字数，注意是字数，其用每一位对应一个存储单元；当所有存储单元都比较完成之后，此时匹配寄存器中所有值为1所对应的存储单元就是匹配成功的存储单元

当然，肯定会有多个存储单元都匹配的情况，此时就需要排队电路对匹配寄存器的输出进行排队，一个常用的方法就是只保留匹配寄存器中位置最前的1，将这个1对应的存储单元的数据输出到数据寄存器中

上图中还有一个标志位PF，PF是匹配寄存器中的所有位按位或的结果，当PF = 1的时候意味着数据寄存器中的内容就是匹配的结果，但是当PF = 0的时候就说明没有匹配到存储单元

除上述之外，相联存储器也可以按照传统的按地址访问，当屏蔽寄存器中的屏蔽码的值全为零的时候，表示检索寄存器被屏蔽，此时输出的AE信号为低电平，这时地址译码器开始发挥作用，按照总线送过来的地址来访问存储器

## 3.3.2 相联存储器的存储元

不是重点，看看书即可

# 3.4 高速缓存存储器Cache

## 3.4.1 Cache的工作原理

### Cache的工作

与主存相比，高速缓存器Cache的存取速度快，容量小，价格高，其位于主存和CPU之间，能快速的向CPU提供指令和数据读写以加快程序的执行速度，用于解决CPU和主存的速度不匹配的问题

Cache中的内容是主存的内容的一个子集，其中保存的内容一方面得与主存保持一致，另一方面还要使得CPU需要访存的的指令和数据尽可能在Cache中找到，即在Cache中可以命中，显然命中率越高，CPU的访存速度越接近于Cache的存取速度

Cache和CPU以及主存的连接如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807184939319.png" alt="image-20240807184939319" style="zoom:67%;" />

CPU访问存储器的时候是按照字或者字节进行的，但是Cache和主存因为程序的局部性原理都是按照块进行逻辑组织的（详见OS），它们之间以块进行内容交换，一个块一般是若干字，一般是定长的，主存和Cache的块的大小相同

CPU对存储器的读操作次数要远大于写操作，下面我们就以读操作来介绍Cache的工作原理

首先，CPU访存的时候面对的是主存空间，因此给出的地址就是主存的地址，此时Cache和主存同时收到这个地址，Cache收到地址之后需要进行地址变换操作，即将主存的地址变换成为Cache的地址，同时这个变换地址的操作还可以判断本次需要访问的内容是否装入到了Cache中（是否命中）

如果CPU需要的指令或者数据就在Cache中，则这些数据直接从Cache送入CPU中，如果不再Cache中，则指令或者数据仍然从主存中获得，并通过地址映射机制将数据所在的块送入到Cache中的指定位置；并且如果Cache已满，此时还需要替换策略将Cache中的一个旧块替换出去，其基本流程如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807185704032.png" alt="image-20240807185704032" style="zoom:67%;" />

目前大多数的Cache都已经集中到了CPU中，这样Cache的工作速度旧近似于CPU的工作速度，通常Cache还被设计为两级或者两级以上的结构

### Cache的命中率

通常Cache的大小比主存要小很多，但是不能太小，太小的话命中率很低，但是也不能太大，太多的话成本太高并且命中率也不能再提升

Cache的命中率H是CPU再访存的时候在Cache中找到所需的信息的概率，假设CPU访问了N此存储器，其中在Cache中命中了N1次，没有命中N2次那么命中率就有：
$$
H = \frac{N_1}{N} = \frac{N_1}{N_1 + N_2}
$$


显然H越接近于1，CPU访存速度越接近于Cache工作速度，当然也就越好

### Cache的主要指标

**（1）失败率F**

也就是CPU在Cache中没有找到信息的概率
$$
F = 1 - H
$$


**（2）平均访存时间Ta**

指CPU单次访存的平均时间：
$$
T_a = HT_c +(1 - H) T_m
$$
这是一个期望值，上式中Tc是指Cache的存取时间（也被称为命中时间），Tm是主存的存取时间

**（3）加速比SP**

值主存的存取时间与平均访存时间的比值：
$$
S_P = \frac{T_m}{T_a} = \frac{1}{(1 - H) + H\frac{T_c}{T_m}}
$$
**（4）访存效率e**

指Cache的存取时间与平均访存时间的比值：
$$
e = \frac{T_c}{T_a} = \frac{1}{H + (1 - H)\frac{T_m}{T_c}}
$$

## 3.4.2 Cache的设计要素

### 地址映射与地址变换

**地址映射**机制就是解决如何将主存的地址映射到Cache地址空间的问题的，通俗来讲，就是将主存中的内容按照某种规则装入到Cache中并建立主存地址与Cache地址的映射关系

当主存将内容装入到Cache之后，当程序运行的时候应该首先将主存地址变换为Cache地址，也就是**地址变换**；采用什么样的地址映射方法，旧必然采用什么样的与这种映射方法相对应的地址变换方法

为了方便进行地址映射，将主存和Cache都分为一个个的块（通常也称为行），每一块由若干的字组成并且每一块的大小都相等；这样主存地址就可以分为块号（块地址）和块内地址，同理Cache也可以分为块地址和块内地址；主存和Cache之间就通过块为单位进行调入调出：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807192001151.png" alt="image-20240807192001151" style="zoom:67%;" />

上图中主存有2^m块，Cache中有2^c块，Cache中每一块都有一个标记字段用以说明是主存中的那一块的副本，比如上图中Cache块中的块1保存的就是主存中块3的副本

当CPU发出访存地址的时候就需要将访存的主存快号与Cache中的**标记字段**进行比较才能判断该地址是否在Cache中命中；通常所有块的标记字段都是统一存放的，比如目录表，区表和块表，这三者是属于不同不同地址映射和地址变换规则中的概念

下面来分别介绍不同地址映射和地址变换规则

#### （1）全相联映射以及地址变换

全相联是指主存中的每一块都可以映射到Cache中的任意一块：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807192737408.png" alt="image-20240807192737408" style="zoom:67%;" />

这种映射方式最灵活，并且Cache的利用率最高，但是成本也最高

在全相联的映射下，主存地址被分为两个部分（CPU给出的地址），如上图为例，主存地址的高m位表示主存块号，表示分为了2^m个块，用符号B表示

主存地址的低n位表示块内地址用符号W表示

Cache地址也分为两个部分

Cache地址的高c位表示Cache块号，用符号b表示

Cache地址的低n位表示块内地址，用符号w表示

通常用**目录表**来记录主存块与Cache块之间的映射关系，并将目录表放在一个相联存储器中（相联存储器可以通过内容访问存储器）

目录表中的每一个存储字分为三个部分：主存块号，Cache块号，有效位；有效位表示目录表中主存块号和Cache块号建立的映射关系是否有效，并且目录表中一共存放有2^c个存储字，也就是每一个Cahce块都会在目录表中对应一个存储字，地址变换过程如下：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240807194110271.png" alt="image-20240807194110271" style="zoom:67%;" />

（1）当一个主存块被调入到Cache中时，此时同时将主存的块号和Cache的块号存入目录表中，并将有效位置为1，这是一个在相联存储器中的目录表写的过程

（2）当CPU提供一个访存地址时，地址变换就是根据CPU提供的访存地址（主存地址）中的主存块号根据数据内容查找相联存储器中的目录表的过程

（3）如果发现目录表中有这个主存块号并且有效位为1，说明命中，此时将Cache的块号换掉内存地址中的主存块号变成Cache的地址访问Cache

#### （2）直接相连映射以及地址变换

直接相连映射是指主存中的块只能映射到Cache中某个固定的块中，比如，主存块号和Cache中的块号的对应如下：
$$
b = B mod 2^c
$$
主存中的块号只能放在其模2^c的Cache的块中，比如主存中的第0，2^c, 2^{2c}只能存放到Cache中的第0块中，而主存中的第1，2^c + 1, 2^{2c} + 1只能映射到Cache中的第1块如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808165356905.png" alt="image-20240808165356905" style="zoom:67%;" />

在直接地址映射中，主存的地址被分为三个部分：区号E(t位)，区内块号B(c位), 和块内地址W(n位)

通常使用区表来存储主存与Cache的映射关系，区表中的每个存储字包括两个部分：主存区号和有效位；有效位表示区表中的主存块是否已经装入了Cache中，并且区表中有$2^c$个存储字，存储字的字数与Cache中的块数相等，区表一般用一个更小的高速缓存存储器存放

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808165935539.png" alt="image-20240808165935539" style="zoom:67%;" />

下面来介绍地址变换过程

CPU发出的访存地址被分解为三个部分：主存区号E，区内块号B，和块内地址W三个部分，首先以区内块号B为地址去访问区表，然后如果区表中的对应字有效则比较区号和CPU发出的主存区号E，这里采用区号以及比较区号的原因就是处于不同区的一系列主存块号是一样的，根据上文中的模运算，B1, B2相等映射到Cache中同一个快处，所以需要用区号加以区分，看看这个块号对应的字段是否服务于自己的区

如果相同，则表示命中，就是这个区的主存块，此时就可以访问Cache了，此时就由区内块号B根据上文中的映射关系找到Cache中的块号b，接着结合根据块内地址W直接访问Cache即可

如果不相同，则表示没有命中，此时就直接访问内存了，并将内存中的一个主存块调入到Cache中，将这个主存的区号E存入区表，并置有效位为1

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808171356085.png" alt="image-20240808171356085" style="zoom:67%;" />

直接相联映射方式的实现简单，地址变换速度快，区表使用SRAM，价格低，但是由于主存中的一个块只能对应Cache中的特定的块，这就带来Cache中的空间使用率不高的问题，并且如果巧合的话CPU发出的地址总是访问不同区中总是相同的主存块号，那样就会造成命中率不高

#### （3）组相联映射及其地址变换

组相联是全相联和直接相连的折中方案

主存和Cache中的块都先分组，并且主存和Cache中每组的块的数量相同，在地址映射的时候，组间采用直接相联映射，组内采用全相联映射；简单来说就是主存的组与Cache中的组有固定的映射关系，但是主存中一个组中的块可以自由存放在对应Cache一个组中的任意位置处

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808172440762.png" alt="image-20240808172440762" style="zoom:67%;" />

上图中Cache被分成了$2^u$个组，每个组中都有$2^v$个块

主存中共有$2^s$个区，每个区中有$2^u$个块，主存中每个区的第$i$组都只能映射到Cache中的第$i$组，在组内采用全相联映射，每个块可以映射到Cache第i组的任意一块

组相联映射由块表记录从主存地址到Cache地址的映射关系，不过这个块表由$2^u$个相联存储器组成，也就是一个相联存储器对应主存中一个不同的区对应相同的Cache中的组的主存中的组，因此有$2^u个$相联存储器，比如某个相联存储器服务于主存中的组0（区0），组2^(u)（区1），...

每个相联存储器都有$2^v$个存储字，对应一个组中的$2^v$个块，每一个存储字服务于一个块，每一个存储字有区号E，组号G，组内块号B和Cache块号b，以及有效位字段

CPU发出的访存地址被分为区号E，组号G，组内块号B和块内地址W四个部分

而Cache的地址可以分为组合g，组内块号b和块内地址w三个部分，CPU访存以及地址变换过程如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808175456675.png" alt="image-20240808175456675" style="zoom:67%;" />

首先，CPU发出的内存地址被分为四个部分：（1）区号E（2）组号G（3）组内块号B（4）块内地址W

然后利用主存地址中的组号G来选择组表，跟直接相联中利用第二级地址B选择区表中存储字的原理一样，不同区号的组号G可以对应同一个相联存储器，注意不同的区都对应一串相同的组号G，这一串组号G与Cache中的组号一致

所以接下来需要将CPU发出的地址中的区号E以及组内块号B在块表中进行相联比较，这个是相联存储器的一个按内容访存的工作，比较E是为了看看这个相联存储器的块表是不是服务于这一个区，这一步跟直接相联比较E的原因一致，比较B是为了看看在服务于这个区的相联存储器中是不是将主存组内中的一块B放入了Cache中，这个比较原因于全相联的比较一致

如果命中，就用块表中的字段b替换掉CPU发出的主存地址中的B，组号与Cache一致，不用替换，块内地址偏移也不用替换，得到的G, b，W就是Cache中对应的地址g, b, w了

因为一个相联存储器可以服务于主存中的多个区，所以组相联映射既可以避免全相联方式下的大量的相联存储器，因此降低了成本

同时组相联存储器在一个组中采用全相联映射，这样就可以充分利用一个相联存储器中的空间，一个块不必每次都在Cache中同一个位置，因此Cache中对于一个块来说可以存放的位置就增加了，不必每次换来换去，旧的块也可以保存在Cache中，很显然这样就提高了CPU的命中率

#### 两个例题

![image-20240808181713288](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808181713288.png)

所谓标记字段，就是表中的存储字为了记录Cache中的存放内容对应主存中的哪个块而增加的信息

在全相联映射中就是目录表中的主存块号

> 全相联中的目录表就是一个相联存储器，直接按照CPU给出的块号按内容查找目录表中的一个存储字中的块号

在直接相联映射中就是块表中的区号

> 直接相联映射中，通过CPU给出的区内块号B按地址区去查块表，块表中的块号E才能说明到底是哪个区的块，因为不同的区块号B可能是一样的

在组相联映射中就是一个相联存储器（块表）中的区号和组内块号

> 组相联存储器中通过组号去查是哪个相联存储器，然后通过区号判断这个相联存储器是否服务于这个组，接着通过相联访存根据组内块号看看这个块是否在Cache中

（1）直接相联的标记字段就是区号，区号的位数就是主存中可以划分为多少个区，主存中一共有$2^{32} / 16 = 2^{18}$个块，一个区的块数与Cache中的块数一样，因此可以划分为$2^{18} / 2^{12} = 2^{16}$个区，所以区号的位数就是16位

（2）2路组相联就是一个组中有两块，所以组内块号就是1位，Cache中一个组的块数与主存中的一个组的块数一样，所以Cache中一个组也有两块，所以Cache中就可以有$2^{12} / 2 = 2^{11}$个组，同理，一个区中的组数应该与Cache中的总组数一样，所以一个区中应该有$2^{11}$个组，主存中两块组成一个组，所以主存中一共有$(2^{32} / 2^{4}) * \frac{1}{2} = 2^{27}$个组，所以应该有$2^{27} / 2^{11} = 2^{16}$个区，所以区号的位数就是16位，加上一位的块号，所以标记位就是17位

其实可以直接看主存的地址格式得到，32位的主存地址格式如下：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808191145519.png" alt="image-20240808191145519" style="zoom:50%;" />

W是块内偏移，因为一个块的大小是16字节，所以W就是4位，B是组内块号，一个组两块，因此B就是1位，G是区内组号，主存中的一个区与Cache中的区组数相等，所以就是11位，那剩下的E就是32 - 11 - 1 - 4 = 16位

所以标志位就是E + B就是17位了

（3）同第二问，W是4位，B是2位，G是Cache中组数，即$2^{12} / 2^2 = 2^{10}$因此就是10位，所以E就是16位，所以标志位就是16 + 2 = 18位

（4）全相联的主存格式：

块号B + 块内地址W，块内地址4位，所以B就是32 - 4 = 28位

**第二个例子**

![image-20240808191821993](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808191821993.png)

同上面的例子，主存地址划分为：

E（区号） + G（区内组号）+ B（组内块号）+W（块内偏移）

一个块128B即$2^7$B，所以W = 7位

一组4块，所以B = 2位

Cache中有$2^{6} / 2^2 = 2^4$组所以G = 4位

主存中有$4096 * 128 = 2^{12} * 2^{7} = 2^{19}$，所以总的主存地址位数就是19位，所以E = 6位

6 + 4 + 2 + 7 = 19位

### 替换算法

替换算法解决的问题就是当有新的块需要调入Cache但是Cache中已经没有空闲位置了，此时应该将哪一块调出的问题

在直接相联映射中替换策略很简单，因为主存中的块只能放在固定的位置，将这个位置的块换出去即可，但是对于全相联映射和组相联映射，就必须考虑替换算法让Cache的命中率最高，也就是我们得保证替换出去的块最近一段时间没有被使用才行

主流的替换算法包括下面几种

#### （1）随机算法

这种算法不考虑每个块被使用的情况，随机选择一个块替换出去，其实现简单且速度块，但是缺点很明显，其没有考虑程序的局部性，也没有考虑到每个块的使用情况，随意替换出去的块可能马上就要使用，这就降低了Cache的命中率和工作效率

#### （2）先进先出算法（FIFO，First In FIrst Out）

这个算法同样不考虑每个块的使用情况，当需要替换的时候将最先调入Cache的块（也就是停留在Cache中时间最长的块）替换出去

其不在意块的使用情况，因此硬件实现也比较简单；但是很显然，如果一个块被使用的次数很高，将其调出之后它马上又要被使用，那就影响了Cache的命中率了

一般而言，对于线性程序其数据的访问与时间呈一个明显的线性相关，所以对于这样的程序采用先进先出算法，命中率很高

#### （3）近期最少使用算法（LRU，Least Recently Used）

这种算法以Cache中每个块的使用情况为依据，在需要替换的时候将近期使用次数最少的块调出去，这种算法非常好的反映了程序的局部性原理，对于循环程序来讲Cache具有很好的命中率，但是LRU需要记录块中每块的使用情况，所以算法的开销比较大，实现较难

#### （4）最不经常使用算法（LFU，Least Frequently Used）

这种算法的思想是将访问次数最少的块替换出去，其与LRU算法非常类似，但是区别在于当执行替换的时候将访问次数最少的块替换出去，**同时将所有块的访问次数归0**

其缺点是只能反映两次替换时间间隔的使用情况，而不能体现一个近期时间段内块的使用情况

#### 一个例题

![image-20240808193910428](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808193910428.png)

其执行中Cache中每块的情况以及命中情况（打勾表示命中）如下所示，第一个表格是FIFO算法：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240808194153350.png" alt="image-20240808194153350" style="zoom:67%;" />

### Cache写操作以及一致性

Cache中的内容是主存的副本，因此必须与主存的内容保持一致，因此这里的一致性涉及的就是写操作，也就是更新主存内容的算法；

导致Cache中的内容与主存内容不一致主要有以下两个原因：

（1）CPU对Cache执行写操作但是没有立刻写入主存

（2）IO设备或IO处理写主存但是没有同时写入Cache

下面有两种写操作：

#### 写直达法

这种策略是指CPU在执行写操作的时候同步写入Cache和主存，于是当Cache中某个块被踢出的时候就不用再重新写回到主存了

这样做的优点是硬件实现简单，Cache和主存的内容始终保持一致，Cache中只涉及有或无的问题，但是内容都是一致的；缺点很显然，同时写入主存那每次更新Cache中内容的时候都访问主存速度就很慢

#### 写回法

写回法是指CPU执行写操作的时候只写入Cache，只有当这个块被踢出Cache的时候再将这个块写入到主存中

很显然，这种做法的优点就是减少了写入时的访问主存操作，提高了速度，但是很明显，这就这样做会导致Cache中的数据与主存中的数据内容不一致，一般来讲Cache中块的内容比主存中的内容更新一些，这样就很容易导致数据出现问题，影响系统可靠性

当然，对于一个在主存和Cache中都已经存在的块，当再次写回的时候又可以采用两种策略

（1）简单写回法，不管这个块是否在Cache更新过都写回到主存中

（2）标志位写回法，只有这个块在Cache中被更新过了再写回到主存中

显然，写回法同时也大大增加了硬件实现的复杂度，下面来说明在写操作时CPU命不命中时的处理

（1）如果CPU在写操作时命中Cache，则就按照上述两种策略更新Cache即可

（2）如果CPU在写操作时没有命中Cache，则又分为两种方法：

i 不按写分配法，当CPU写不命中的时候，只执行对主存的写入操作

ii 按写分配法，当CPU写不命中的时候，先执行写入主存的操作，然后将主存中的块调入到Cache中，一般写回法就是执行按写分配的模式的

### 多级Cache

早期的计算机通常就只有一级Cache，但是为了提高系统的性能越来越多的系统中采用多级Cache，下面介绍两种多级Cache

#### 片内和片外Cache

随着集成电路的发展，Cache通常被集成在CPU中，称为片内Cache，其特点就是如果访问的数据在片内的Cache中，则CPU的访问将在CPU内部进行，不需要总线传输数据，因此存取速度非常快

但是片内的Cache的容量通常不会很大，为了提高命中率，通常在CPU外部再增加一个容量较大的Cache，这样CPU内部的Cache称为一级Cache（L1 Cache），而片外的Cache称为二级Cache（L2 Cache）

在这两种Cache结构中，第二级Cache的容量比第一级Cache多得多，但是第一级Cache的保存的内容要比第二级Cache多，只有CPU访问第一级Cache没有命中的时候才会去访问第二级Cache

在两级Cache中CPU的平均访存时间为：
$$
T = h_1C_1 + (1 - h_1)h_2C_2 + (1 - h_1)(1 - h_2)M
$$
上式中h1是一级Cache的命中率，h2是二级Cache的命中率，C1是一级Cache的存取时间，C2是二级Cache的存取时间，M是主存的存取时间，上式是命中一级Cache，没有命中一级Cache但是命中二级Cache，两级Cache都没有命中的加权结果

#### 数据Cache和指令Cache

根据程序的局部性原理，指令的存放呈现非常明显的局部性，也就是下一条指令与正在执行的指令很可能存放在主存中的相邻的位置

并且大多数的循环程序都很小，因此可以将整个循环代码都存放在Cache中，这些代码在一段时间中可能都会被访问

但是CPU对数据的访问具有随机性，可能现在访问这条数据，那下条数据可能就不再这条数据旁边，因此如果将指令和数据都放入一个Cache中就会影响到这块Cache的命中率（主要是数据影响了命中率）因此就把指令和数据分别存放到两个Cache中，称为指令Cache和数据Cache

这样指令具有局部性，那这块指令Cache的命中率就不会被影响，而数据Cache中存放数据的空间变大，也会增加一些这块数据Cache的命中率

# 3.5 辅助存储器

主存通常价格昂贵并且容量不会很大，并且在早期的计算机中的SRAM和DRAM都具有电易失性，所以引入了辅助存储器以扩大整个系统的存储容量，并提供长期保存信息的能力

## 3.5.1 辅助存储器概述

### 磁表面存储器的工作原理

写入操作，磁头中线圈的电流方向不同，磁化单元被磁化的极性就不同，这样就可以记录（写入）二进制位0， 1

读取操作，磁化单元上的磁化状态不同，感应电动势也不同，这样就可以区分磁化单元上是0还是1

### 磁表面存储器的记录方式

在磁表面的磁记录方式就是编码方式，**也就是按照一定的规则将二进制位串变换为记录介质上相应磁通翻转形式**，不同编码方式的存储性能不同，编码方式设计的主要目标有：更高的编码效率，更高的自同步能力和更高的读写能力

编码效率是指位密度与磁化翻转次数之比，位密度是指磁道单位长度上能记录的二进制代码数，磁化翻转次数就是磁道单位长度上磁性材料的翻转次数，也就是**磁道单位长度上磁性材料磁场方向从一个极性转向另一个极性的次数**，很显然，如果一次翻转表示两位数据就比一次翻转表示一位数据的编码效率要高

下面是几种常见的编码方式

#### （1）归零制（RZ）

磁介质在写入前处于未磁化的状态，磁头线圈中通正向电流时写1，通负向电流时写0，并且每写一位电流都要归零，其写入电流波形图如下所示：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811112256865.png" alt="image-20240811112256865" style="zoom:67%;" />

通过上面的波形图可以看到，每写一位电流都必须归零因此每一个位单元之间都会存在没有磁化的区域，这样记录密度就很低，而且这种编码方式遇到1位的1之后还会归零，这也是一次磁化翻转，其编码效率也很低

归零制的编码是具有自同步能力的，所谓自同步能力，就是指在数据传输或存储过程中，即使在出现干扰、错误或长时间的信号平稳区域时，系统能够自动保持数据的正确同步；

而归零制的编码其通过每一位都归零的翻转来表示一位数据的结束，从而可以区分数据到底是结束还是长时间的静默，从而准确识别数据的边界；同时其每一位结束之后的翻转同样可以被当作一个过渡信号，这样就可以被接收端当作一个时间标记建立同步点，如果出现了长时间的单一电平，接收端就可以认为可能是数据出现了问题，从而重新将数据对齐同步

归零制编码由于磁盘区域中有没有磁化的地区存在，这些地区容易被旁边周围的磁化地区叠加干扰影响，因此其抗干扰的能力就弱一些

#### （2）不归零制（NRZ）

不归零制是指，线圈中通正向电流时写1，通负向电流时写0，每写一位电流不归零，只有遇到数据位的变化才进行翻转：

![image-20240811161727659](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811161727659.png)

很显然，归零制中的磁盘不存在没有磁化的区域，所以记录密度要比归零制高，并且翻转次数也比归零制要低，因此记录效率也更高；同时其线圈中始终存在电流，所以抗干扰的能力比归零制要强

但是其没有自同步能力，无法区分数据的边界，这样就容易造成误码

#### （3）见1就翻的不归零制（NRZ1）

这种编码方式是指每写入一个1，电流就翻转一次，但是写入零的时候电流就不变：

![image-20240811162209050](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811162209050.png)

这种记录方式可靠性显然比NRZ要高一些，因此记录1的翻转提供了更多的过渡标记

#### （4）调相制（PM）

写1的时候在位周期的中心点变化一次（由正变负或者由负变正），同样写0的时候在位周期的中心点变化一次（由正变负或者由负变正）；并且在写入相同的代码（连续的1或0）的时候每次都在位周期的交界处翻转一次（不仅在周期中心翻转，还要在周期的交界面处翻转）

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811162908543.png" alt="image-20240811162908543" style="zoom:67%;" />

这种编码的抗干扰能力比上述就更强，并且其通过交界面连续的翻转提供了更强的自同步能力，能够很好区分数据的静默还是连续的数据

#### （5）调频制（FM）

这种是在写1的时候在周期的起始和周期中心处翻转一次，写0的时候只在周期的起始翻转一次：

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811165452553.png" alt="image-20240811165452553" style="zoom:67%;" />

其记录高，并且同样具有自同步能力

#### （6）改进调频制（MFM）

写1时，电流只在周期中心翻转一次，写单个0时电流不变，连续写0时电流在周期起始翻转一次，如上图所示

这种编码的记录密度比调频制提高一倍，因为如上图所示，同样的10两个位，FM从开始到0的结束需要翻转三次，这样用四个磁性材料才能表示翻转三次，但是MFM只用翻转一次，这样只用两个磁性材料就可以表示一次翻转，所以大致来看记录密度就是FM的一倍

并且这改进调频制也具有自同步能力

#### 校验码

在磁表面通常使用校验码来发现和纠正正在存储的和传输中的差错；也就是在数据的后面加上冗余码，循环冗余校验码是磁表面存储器中通常使用的校验码，也称为CRC码，其原理在数电和计网中会有详述，这里不再说明

## 3.5.2 硬磁盘存储器

硬磁盘存储器，其实也就是硬盘，是一种利用涂有磁介质的旋转圆盘上进行数据存储的辅助存储器，其通常与主存一起构成虚拟构成虚拟存储器来扩充主存的容量

### 磁盘的工作原理

不赘述，不是重点

### 磁盘上数据的存储

一块硬盘通常是由按照在一个轴上的一个或多个磁盘片组成，每个磁盘片的表面（单面或者双面）都涂有磁性材料作为记录介质，在进行读写操作的时候磁盘片就会随轴进行高速旋转来进行定位，并通过磁头进行读写操作

硬盘由一组盘片构成，称为盘片组，盘片组固定在一个轴上（主轴），盘片中心是空心的，不能记录信息；

每个盘片的记录区被划分为一个个的同心圆，这些同心圆称为**磁道**，每个同心圆的之间的间隔相等，磁头最靠近主轴的表面，也就是线速度最小的地方不记录任何信息称为启停区或着陆区，启停区的外面才是数据区；通常从最外侧的磁道开始编号，起始磁道的编号就是0，在硬盘中就通过0磁道检测器来完成磁道的初始定位

不同盘片上的相同的磁道号形成了一个圆柱，称为**硬盘的圆柱面或柱面**，一个硬盘的柱面数显然是和一个盘面上的磁道数是相等的；每个柱面上的磁头（每个柱面都有磁头）从上到下从0开始进行编号；注意对文件的写入是按照柱面进行的，也就是磁头的读写数据先从同一个柱面的0磁头开始操作，然后依次往下将整个柱面（处于不同盘面）全部读写完成之后再到下一个柱面；这样做的目的是为了提高读写效率，因为选取不同的磁头只是需要电子操作，而选择柱面则需要磁头的机械移动，显然前者更快

一个磁道通常被分为若干段的圆弧线，称为扇区（Sector），其只是磁道上的一段弧线；一个磁道上的所有扇区都是等长的；**硬盘以扇区为单位进行存取，也就是硬盘的最小可寻址单位是扇区，而不是主存中的字或者字节**

<img src="https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811173441078.png" alt="image-20240811173441078" style="zoom:67%;" />

磁盘的定位和划分有硬件和软件两种方式，不过无论是哪种方式，为了标识一个磁道信息的起始都会在磁道的起始处打一个索引空，这样通过光电的方式获得一个电脉冲，称为0索引；这样随着磁盘的旋转就很容易识别扇区的扇区号

硬分区通常采用定长的方式，也就是每个扇区中存放的数据块大小固定；**这种记录方式虽然外磁道的周长大于内磁道的周长，但是存放的数据块的大小是固定的**；很显然，其对磁道的空间利用率不高（毕竟内外还是有差异的）

软分区可用定长和不定长两种方式，不定长是指扇区（称为记录块）中存放的数据块大小可变；这种记录格式中外圈磁道可以比内圈磁道存储更多的字节，空间利用率更高

在对磁盘上的数据存储进行定位的时候通常采用如下的地址格式：

![image-20240811174532980](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811174532980.png)

上图中的驱动器号是指系统中存在多块硬盘的时候指出数据所在的硬盘编号

柱面号，也就是磁道号，指出数据所在的磁道

盘面号，其实也可以用磁头号表示，用以说明读写数据正在使用的磁头

扇区号，说明是在对哪个扇区进行读写的

磁盘在进行读写操作的时候磁盘驱动器首先要进行寻道操作，即确定需要操作的柱面

然后，定位驱系统带动磁头进行径向操作，将磁道移动到对应的磁头

完成定位之后主轴带动磁盘组进行旋转，将需要读写的扇区移动到磁头下方（或者双面磁盘中磁头的上方）

最后读写控制系统控制磁头进行读写

早期的硬盘在进行数据读写的时候采用的是CHS进行组织，但是这种组织方式导致外圈的磁道记录密度过低，整体硬盘的容量不高

为了外圈的磁道记录密度，线代硬盘采用的是ZBR的记录方式，这种方式中外圈磁道划分了更多的扇区，从而提高的硬盘的整体容量

在ZBR的记录方式下，磁盘外圈的磁道的道容量大于内圈的道容量，因此在磁盘的转速不变的时候外圈的读写速率是显然大于内圈的，通常磁盘的0磁道位于最外圈，磁盘中按照操作系统的时候就安装在最外圈，这也是新安装操作系统之后速度更快的原因之一

### 硬盘的主要参数

#### （1）容量

一个硬盘的容量是指所有盘面上的全部磁道中存储信息的总和

硬盘的容量与记录密度相关，记录密度是指单位面积或者单位长度上可以存储的二进制位数，通常使用道密度和位密度来衡量

道密度是指沿着磁盘径向上单位长度的磁道数量单位TPI，一个盘片的磁道总数为：
$$
一个盘片的磁道总数 = 道密度 * 磁道的有效半径
$$
位密度是指盘面磁道上单位长度能够记录的二进制位的数目，单位位bpi，一个磁道的总的容量为：
$$
一个磁道总容量 = 位密度 * 磁道的周长
$$
CHS硬盘的总容量为（也就是定长的记录格式）：
$$
硬盘总容量 = 硬盘个数 * 一个硬盘的记录面数 * 一个盘面的磁道数 * 一个磁道的容量
$$
展开就是：
$$
硬盘总容量 = 硬盘个数 * 一个硬盘的记录面数 * (道密度 * 盘面的有效半径) * (位密度 * 磁道的周长)
$$
上述计算得到的是**硬盘的非格式化容量**，也就是硬盘在物理上可以记录的二进制的位数

但是磁盘（包括硬盘和软盘）必须格式化才能使用，所谓格式化就是在存储前进行处理，比如划分好区域，一级建立索引等等，格式化包括物理格式化和逻辑格式化

物理格式化是对磁盘的表面进行处理，在磁盘上建立标准的磁盘记录格式，包括划分磁道和扇区等

逻辑格式化是指在磁盘上建立一个系统存储区域，包括引导记录，文件目录，文件分配表等等，这个工作由操作系统的文件管理系统完成

格式化的容量显然是小于非格式化容量的，格式化容量的计算方式如下所示：
$$
硬盘的格式化容量 = 硬盘总容量 = 硬盘个数 * 一个硬盘的记录面数 * 一个盘面的磁道数 * 一个磁道扇区数 * 一个扇区的容量
$$
与格式化的记录方式相比起差异在于格式化之后只能在划分好的扇区中存储数据，因此上述公式中使用的是扇区和扇区容量

下面看一个例子：

![image-20240811182208939](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240811182208939.png)

注意题中的内径和外径指的都是直径

首先是一个磁道的容量，内存位密度知道，而定长记录方式就是所有磁道的容量都是一样的，所以就是：
$$
400 * 2 * \pi * (\frac{22}{2})b = 27632b = 3454B
$$
然后是一个盘面的磁道数：
$$
40 * (33 - 22) / 2 = 220
$$
得到每个盘面的容量：
$$
220 * 3454B = 759880 B
$$
整个硬盘系统的盘面数为2\*（5\*2 - 2）= 16

所以整个硬盘的容量就是：
$$
16 * 759880B = 12158080B = 11.59MB
$$

#### （2）传输速率

硬盘的传输速率主要取决于以下几个因素

磁头定位道磁道的时间，需要访问的扇区旋转到磁头的上面（或下面）的时间，以及磁头进行读写操作所需的时间

上述时间可以由平均寻址时间和数据传输率来衡量

**（1）平均寻址时间**

平均寻址时间是磁头从起始位置到达目标磁道位置，并且定位到目标磁道上的目标扇区的所需的平均时间

![image-20240813165616842](https://typora-1310242472.cos.ap-nanjing.myqcloud.com/typora_img/image-20240813165616842.png)
