

# 特征值与特征向量，相似与对角化

## 关于特征值的重数k与n - r(A - $\lambda$ E)的关系

如果$\lambda$是A的特征值等价于|A - $\lambda$E| = 0，|A - $\lambda$E| = 0构成了一个与$\lambda$有关的多项式，这个多项式称为特征多项式，$\lambda$就是这个特征值的解，某个$\lambda$解的重数称为特征值$\lambda$的重数k

如果一个向量$\eta$是A的特征向量等价于$\eta$是(A - $\lambda$E)X = 0的**非零解**，n - r(A - $\lambda$ E)是方程(A - $\lambda$E)X = 0所对应的基础解系的个数，注意这里的基础解系很显然是不包括零向量的，所以$n - r(A - \lambda E)$就是特征值$\lambda$对应的特征向量的极大无关组的个数，**因此$n - r(A - \lambda E)$就是特征值$\lambda$对应最多的线性无关的特征向量的个数**

我们有如下关系，即特征值的重数大于等于这个特征值对应的其次方程组的基础解系的个数：
$$
k >= n - r(A - \lambda E)
$$
**所以特征值$\lambda$对应的一组线性无关特征向量，这组向量的个数最多是k个，即$\lambda$的重数**

> 所以如果我们知道了某个特征值$\lambda$的重数是1，并且知道了一个特征向量$\eta$，那么这个特征向量就是$\lambda$所对应的所有特征向量的极大无关组，所以就可以用$\eta$来表示所有的特征向量，即$c\eta$就是$\lambda$对应的特征向量，其中c != 0

因此当每个特征值都有$k = n - r(A - \lambda_k E)$的时候说明每一个特征值$\lambda _k$都对应了k个线性无关的特征向量，由于所有特征值的重数之和为n，所以每个特征值对应的k个线性无关的特征向量加起来一共有n个，根据如下定理：

> 如果有一组的特征向量$\eta_1, \eta_2, ... \eta_s$线性无关 **等价于** 这里面属于同一个特征值的部分组特征向量线性无关

所以上述n个特征向量一定线性无关，所以当每个特征值都有$k = n - r(A - \lambda_k E)$的时候矩阵A就对应了n个线性无关的特征向量，因此A就可以相似对角化

> 当然还有一个推论，若A的特征值两两互不相同，说明每个特征值的重数都为1，显然每个特征值对应的线性无关的特征向量个数就是1，所以A的这n个特征值对应的n个特征向量就一定线性无关，所以A就一定可以相似对角化

